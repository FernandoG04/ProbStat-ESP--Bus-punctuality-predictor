{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<a style=\"flex: 1; text-align: left;\" href=\"./2_3_Error_term.ipynb\">← Previous: 2.3 Estimation of the Error Term</a>\n",
    "<a style=\"flex: 1; text-align: right;\" href=\"./2_5_Model_building.ipynb\">Next: 2.5 Model Building →</a>\n",
    "</div>\n",
    "\n",
    "### 2.4 Tests for the Significance of the Regression\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; line-height: 2\">\n",
    "\n",
    "There are multiple tests that can be used to determine the significance of the regression. The most common are the t-test and the F-test, described below.\n",
    "\n",
    "#### 2.4.1 Hypothesis Testing with the t-test\n",
    "\n",
    "The t-test is used to test the significance of the regression coefficients $\\beta_i$. Essentially, the t-test is used to determine whether the estimated value of a coefficient $\\beta_i$ is significantly different from zero, i.e. whether the regressor $x_i$ belongs in the model. The t-test is  defined as follows<sup><a href=\"#footnote2\">2</a></sup>:\n",
    "\n",
    "$$H_0: \\beta_i = 0$$\n",
    "$$H_1: \\beta_i \\neq 0$$\n",
    "\n",
    "The test statistic is defined as:\n",
    "\n",
    "$$\\begin{equation} \\tag{2.4.1}\n",
    "\\boxed{t = \\frac{\\hat{\\beta_i}}{\\sqrt{\\sigma^2c_{jj}}}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\beta_i}$ is the estimated value of $\\beta_i$, $\\sigma^2$ is the variance of the error term, and $c_{jj}$ is the $j$ th diagonal element of the matrix $(X'X)^{-1}$. The test statistic is t-distributed with $n-p$ degrees of freedom, where $n$ is the number of observations and $p = k+1$ is the number of regressors. The test is performed as a two-tailed test, i.e the null hypothesis is rejected if $|t| > t_{\\alpha/2, n-p}$. In this case, the coefficient $\\beta_i$ is said to be significantly different from zero and is accepted as a regressor in the model<sup><a href=\"#footnote3\">3</a><a href=\"#footnote5\">5</a></sup>.\n",
    "\n",
    "#### 2.4.2 Coefficient of Determination $R^2$\n",
    "\n",
    "The coefficient of determination $R^2$ is a measure of the goodness of fit of the regression model. It is defined as the fraction of the total variation in the dependent variable $y$ that is explained by the regression model<sup><a href=\"#footnote4\">4</a></sup>. The coefficient of determination contains two components: the sum of squared 'errors' ($SS_E$) and the total sum of squares ($SS_T$), i.e, the sum of squared residuals and the sum of squared variations of the dependent variable $y$ around its mean, respectively. The coefficient of determination is defined as<sup><a href=\"#footnote2\">2</a></sup>:\n",
    "\n",
    "$$\\begin{equation} \\tag{2.4.2}\n",
    "{R^2 = \\frac{SS_R}{SS_T} = 1 - \\frac{SS_E}{SS_T}}\n",
    "\\end{equation}\n",
    "$$\n",
    "Where\n",
    "$$SS_E = \\sum_{i=1}^{m} \\varepsilon_i^2 ; \\hspace{.5cm} SS_T = \\sum_{i=1}^{n} (y_i^2 - 1/n \\sum_{i=1}^{n} y_i)^2 ; \\hspace{.5cm} SS_R = SS_T - SS_E$$\n",
    "\n",
    "The coefficient of determination is a number between 0 and 1. In general, this represents the percentage of variability of the data that is explained by the model. However, this is not a good measure of the goodness of fit of the model, as it exclusively increases with the number of regressors in the model. Therefore, the adjusted coefficient of determination is preferred<sup><a href=\"#footnote2\">2</a></sup>:\n",
    "\n",
    "$$\\begin{equation} \\tag{2.4.3}\n",
    "\\boxed{R_{adj}^2 = 1 - \\frac{SS_E/(n-p)}{SS_T/(n-1)}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "This measure penalizes the coefficient of determination for the number of regressors in the model. Therefore, including a regressor in the model will only increase the adjusted coefficient of determination by a significant amount if it significantly improves the fit of the model, thus avoiding overfitting<sup><a href=\"#footnote2\">2</a></sup>. \n",
    "\n",
    "Under the assumptions stated in section 2.2, the t-test and the adjusted coefficient of determination are used to determine the significance of the regressors and the goodness of fit of the model, respectively. They are implemented in variable selection when model building, which is discussed in the next section.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "&nbsp;  \n",
    "&nbsp;  \n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"footnote1\"></a>1: [PennState Eberly College of Science](./5_References.ipynb#1)  \n",
    "<a name=\"footnote2\"></a>2: [Ivan T. Ivanov](./5_References.ipynb#2)  \n",
    "<a name=\"footnote3\"></a>3: [OpenStax](./5_References.ipynb#3)  \n",
    "<a name=\"footnote4\"></a>4: [Heij, De Boer; Franses, Kloep; and Van Dijk](./5_References.ipynb#4)  \n",
    "<a name=\"footnote5\"></a>5: [Mostoufi, Navid; Constantinides, Alkis](./5_References.ipynb#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<a style=\"flex: 1; text-align: left;\" href=\"./2_3_Error_term.ipynb\">← Previous: 2.3 Estimation of the Error Term</a>\n",
    "<span style=\"flex: 1; text-align: center;\">2.4 Tests for the Significance of the Regression</span>\n",
    "<a style=\"flex: 1; text-align: right;\" href=\"./2_5_Model_building.ipynb\">Next: 2.5 Model Building →</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
