{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<a style=\"flex: 1; text-align: left;\" href=\"./1_Introduction.ipynb\">← Previous: 1. Introduction</a>\n",
    "<a style=\"flex: 1; text-align: right;\" href=\"./2_2_Least_square.ipynb\">Next: 2.2 Least Squares Estimation of the Parameters →</a>\n",
    "</div>\n",
    "\n",
    "### 2.1 Multiple Linear Regression\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linear regression is a statistical model that examines a linear predictive relationship between a dependent variable and one (Simple Linear Regression) or more (Multiple Linear Regression) independent variables<sup>[1](#footnote1)</sup>. The dependent variable is also called the response variable, and the independent variables are called the predictor variables<sup>[2](#footnote2)</sup>. The model, is expressed as follows<sup>[2](#footnote2)</sup>:\n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k + \\epsilon$$\n",
    "\n",
    "In this model $Y$ is the dependent variable which is being predicted using $k$ predictors $\\{x_i\\mid i\\in \\N,\\; 1\\leq i\\leq k\\}$. The regression coefficients $\\{\\beta_i\\mid i\\in \\N,\\; 1\\leq i\\leq k\\}$ are associated to the corresponding $x_i$ regressors, indicating the change in $Y$ when a certain $x_1$ is increased while keeping all other predictors constant. $\\beta_0$ is the intercept (or initial value) of the equation. $\\epsilon$ is the error (or noise) term, which takes into account all other unkown factors which influence the dependent variable $Y$ other than the predictor variables $x_i$. \n",
    "\n",
    "The above equation assumes that the relationship between the dependent variable $Y$ and the predictor variables $x_i$ is linear. However, transformations of the predictor variables can be used to estimate non-linear relationships. For example, we can introduce a quadratic term $x_1^2$ and an exponential term $e^{x_1}$ to the equation: \n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2^2 + \\beta_3 e^{x_3} + \\cdots + \\beta_k x_k + \\epsilon$$\n",
    "\n",
    "Although in this equation the relationship between $Y$ and $x_i$ is non-linear, $Y$ is still linear in the coefficients $\\beta_i$. Therefore, this equation is still a linear regression model. \n",
    "\n",
    "In real applications, the true relationship between the dependent variable $Y$ and the predictor variables $x_i$ is usually unknown. The aim of MLR models is to approximate this relationship and estimate the unknown parameters $\\beta_i$ and $\\epsilon$. The most common method to estimate the parameters is the Least Squares method, which will be discussed in the next section.  \n",
    "\n",
    "---\n",
    "<a name=\"footnote1\"></a>1: [PennState Eberly College of Science](./5_References.ipynb#1)  \n",
    "<a name=\"footnote2\"></a>2: [Ivan T. Ivanov](./5_References.ipynb#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<a style=\"flex: 1; text-align: left;\" href=\"./1_Introduction.ipynb\">← Previous: 1. Introduction</a>\n",
    "<span style=\"flex: 1; text-align: center;\">2.1 Multiple Linear Regression</span>\n",
    "<a style=\"flex: 1; text-align: right;\" href=\"./2_2_Least_square.ipynb\">Next: 2.2 Least Squares Estimation of the Parameters →</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
