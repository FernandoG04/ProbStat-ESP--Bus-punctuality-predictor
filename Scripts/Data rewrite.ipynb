{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import urllib.request\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STM Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge STM files and save as a pandas dataframe\n",
    "\n",
    "STM_1_df = pd.read_csv('../Data/Transit data/STM_Data_2021_2022.csv', dtype={0: str, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str})\n",
    "STM_1_df = STM_1_df.dropna(how='all')\n",
    "STM_2_df = pd.read_csv('../Data/Transit data/STM_Data_2023.csv', dtype={0: str, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str})\n",
    "\n",
    "STM_df = pd.concat([STM_1_df, STM_2_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, ligne, dir, id_voy, dep_pl, dep_rl, arr_pl, arr_rl]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows in case the index was copied over\n",
    "\n",
    "original_df = STM_df.copy()\n",
    "STM_df = STM_df.drop_duplicates()\n",
    "\n",
    "removed_rows = original_df[~original_df.index.isin(STM_df.index)]\n",
    "print(removed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2021-10-05\n",
      "1   2021-10-05\n",
      "2   2021-10-05\n",
      "3   2021-10-05\n",
      "4   2021-10-05\n",
      "Name: date, dtype: datetime64[ns]\n",
      "  dep_pl dep_rl arr_pl arr_rl\n",
      "0  00:10  00:10  00:45  00:44\n",
      "1  00:42  00:42  01:17  01:14\n",
      "2  01:14  01:13  01:49  01:44\n",
      "3  05:06  05:06  05:41  05:39\n",
      "4  05:39  05:41  06:14  06:13\n"
     ]
    }
   ],
   "source": [
    "# Change data format from YYYY/MM/DD to YYYY-MM-DD\n",
    "try:\n",
    "    STM_df['date'] = STM_df['date'].str.replace('/', '-')\n",
    "    STM_df['date'] = pd.to_datetime(STM_df['date'],errors='coerce')\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while converting the Date: {e}\")\n",
    "\n",
    "# Verify that the date format is correct\n",
    "print(STM_df['date'].head())\n",
    "\n",
    "# Change time format from HH:MM:SS to HH:MM\n",
    "try:\n",
    "    STM_df[['dep_pl', 'dep_rl', 'arr_pl', 'arr_rl']] = STM_df[['dep_pl', 'dep_rl', 'arr_pl', 'arr_rl']].apply(lambda x: x.str.slice(stop=5))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while slicing the Time: {e}\")\n",
    "\n",
    "# Verify that the time format is correct\n",
    "print(STM_df[['dep_pl', 'dep_rl', 'arr_pl', 'arr_rl']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 165, 0, 0.10); padding:10px;\">\n",
    "Enable this cell to store the STM data as a csv file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STM_df.to_csv('../Data/Transit data/STM_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 165, 0, 0.10); padding:10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Daily data for snow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 165, 0, 0.10); padding:10px;\">\n",
    "This code was used to retrieve all weather data from the Government of Canada website\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the start and end years for the data\n",
    "#yi = 2021\n",
    "#yf = 2023 + 1 \n",
    "\n",
    "# Set the station ID\n",
    "#station = 30165 # Select station ID (Montreal-Trudeau Airport is 30165)\n",
    "\n",
    "# Retrieve daily weather data from the Government of Canada website and store in Individual Files folder\n",
    "#for year in range(yi, yf):\n",
    "\n",
    "#        url = 'https://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&stationID=' + str(station) + '&Year=' + str(year) + '&Month=1&Day=14&timeframe=2&submit=Download+Data'\n",
    "#        filename = os.path.join('../Data/Weather Data/Individual Files', 'daily_montreal_weather_' + str(year) + '.csv')\n",
    "#        try: \n",
    "#            urllib.request.urlretrieve(url, filename)\n",
    "#       except Exception as e:\n",
    "#            print(f\"An error occurred while downloading data for year {year} and month {month}: {e}\")\n",
    "#        time.sleep(5)\n",
    "\n",
    "# Retrieve hourly weather data from the Government of Canada website and store in Individual Files folder\n",
    "#for year in range(yi, yf):\n",
    "   \n",
    "    #if year == 2021:\n",
    "        #mi = 10\n",
    "        #mf = 12 + 1\n",
    "    #elif year == 2023:\n",
    "        #mi = 1\n",
    "        #mf = 9 + 1\n",
    "    #else:\n",
    "        #mi = 1\n",
    "        #mf = 12 + 1\n",
    "    #for month in range(mi, mf):\n",
    "        #if month < 10:\n",
    "            #month = '0' + str(month)\n",
    "        #else:\n",
    "            #month = str(month)\n",
    "        #url = 'https://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&time=UTC&stationID=' + str(station) + '&Year=' + str(year) + '&Month=' + str(month) + '&Day=14&timeframe=1&submit=Download+Data'\n",
    "        #filename = os.path.join('../Data/Weather Data/Individual Files', 'hourly_montreal_weather_' + str(year) + '_' + str(month) + '.csv')\n",
    "        #try: \n",
    "            #urllib.request.urlretrieve(url, filename)\n",
    "        #except Exception as e:\n",
    "            #print(f\"An error occurred while downloading data for year {year} and month {month}: {e}\")\n",
    "        #time.sleep(5)\n",
    "\n",
    "# merge all csv files into one dataframe\n",
    "#all_dailyw = glob.glob(os.path.join('../Data/Weather Data/Individual Files', \"daily_montreal_weather_*.csv\")) \n",
    "#all_hourlyw = glob.glob(os.path.join('../Data/Weather Data/Individual Files', \"hourly_montreal_weather_*.csv\"))\n",
    "\n",
    "#df_all_dailyw = (pd.read_csv(f) for f in all_dailyw)\n",
    "#df_dailyw = pd.concat(df_all_dailyw, ignore_index=True)\n",
    "#df_all_hourlyw = (pd.read_csv(f) for f in all_hourlyw)\n",
    "#df_hourlyw = pd.concat(df_all_hourlyw, ignore_index=True)\n",
    "\n",
    "\n",
    "#store the dataframe as a csv file\n",
    "#df_dailyw.to_csv('../Data/Weather Data/daily_montreal_weather.csv', index=False)\n",
    "#df_hourlyw.to_csv('../Data/Weather Data/hourly_montreal_weather.csv', index=False)\n",
    "\n",
    "# delete all individual csv files\n",
    "#files = glob.glob('../Data/Weather Data/Individual Files/*')\n",
    "#for f in files:\n",
    "#    os.remove(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dailyw = pd.read_csv('../Data/Weather Data/daily_montreal_weather.csv', dtype={0: str, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty columns\n",
    "df_dailyw = df_dailyw.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of interest to match the STM data\n",
    "df_dailyw = df_dailyw.rename(columns={'Date/Time': 'date', 'Snow on Grnd (cm)': 'snow'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format and remove rows with dates that are not in the STM data\n",
    "\n",
    "try:\n",
    "    df_dailyw['date'] = pd.to_datetime(df_dailyw['date'],errors='coerce')\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while converting the Date: {e}\")\n",
    "    \n",
    "df_dailyw = df_dailyw[df_dailyw['date'].isin(STM_df['date'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fer_g\\Documents\\College\\F2023\\Probstat\\ESP\\Scripts\\Data rewrite.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fer_g/Documents/College/F2023/Probstat/ESP/Scripts/Data%20rewrite.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#place the date and snow columns first and remove the rest\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fer_g/Documents/College/F2023/Probstat/ESP/Scripts/Data%20rewrite.ipynb#Y161sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cols \u001b[39m=\u001b[39m df_dailyw\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()  \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fer_g/Documents/College/F2023/Probstat/ESP/Scripts/Data%20rewrite.ipynb#Y161sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m fifth_col \u001b[39m=\u001b[39m cols[\u001b[39m4\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fer_g/Documents/College/F2023/Probstat/ESP/Scripts/Data%20rewrite.ipynb#Y161sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fifth_to_last_col \u001b[39m=\u001b[39m cols[\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fer_g/Documents/College/F2023/Probstat/ESP/Scripts/Data%20rewrite.ipynb#Y161sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cols \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m cols \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {cols[\u001b[39m4\u001b[39m], fifth_to_last_col}]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#place the date and snow columns first and remove the rest\n",
    "\n",
    "cols = df_dailyw.columns.tolist()  \n",
    "fifth_col = cols[4]\n",
    "fifth_to_last_col = cols[-5]\n",
    "cols = [col for col in cols if col not in {cols[4], fifth_to_last_col}]\n",
    "cols = [fifth_col, fifth_to_last_col]\n",
    "df_dailyw = df_dailyw[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place a value of 0 for snow if NaN\n",
    "df_dailyw['snow'] = df_dailyw['snow'].fillna(0)\n",
    "\n",
    "# place a value of Y for snow if >0 and N if 0 or Nan in a new column\n",
    "df_dailyw['snow_yn'] = np.where(df_dailyw['snow'] > 0, 'Y', 'N')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Hourly data for precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourlyw = pd.read_csv('../Data/Weather Data/hourly_montreal_weather.csv', dtype={0: str, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty columns\n",
    "df_hourlyw = df_hourlyw.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of interest to match the STM data\n",
    "df_hourlyw = df_hourlyw.rename(columns={'Date/Time (UTC)': 'date', 'Time (UTC)': 'time', 'Temp (Â°C)' : 'temp', 'Precip. Amount (mm)' : 'precip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change format of date columns to datetime, change from UTC to EST taking into account daylight savings time, change time column to reflect the time in the date column\n",
    "\n",
    "try:\n",
    "    df_hourlyw['date'] = pd.to_datetime(df_hourlyw['date'],errors='coerce')\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while converting the Date: {e}\")\n",
    "\n",
    "df_hourlyw['date'] = df_hourlyw['date'].dt.tz_localize('UTC').dt.tz_convert('America/Montreal')\n",
    "df_hourlyw['time'] = df_hourlyw['date'].dt.strftime('%H:%M')\n",
    "df_hourlyw['date'] = df_hourlyw['date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format and remove rows with dates that are not in the STM data\n",
    "\n",
    "try:\n",
    "    df_hourlyw['date'] = pd.to_datetime(df_hourlyw['date'],errors='coerce')\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while converting the Date: {e}\")\n",
    "    \n",
    "df_hourlyw = df_hourlyw[df_hourlyw['date'].isin(STM_df['date'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the date, time, temp and precip columns first and remove the rest\n",
    "\n",
    "cols = df_hourlyw.columns.tolist()\n",
    "date_col = cols[4]\n",
    "time_col = cols[8]\n",
    "temp_col = cols[9]\n",
    "precip_col = cols[12]\n",
    "cols = [col for col in cols if col not in {date_col, time_col, temp_col, precip_col}]\n",
    "cols = [date_col, time_col, temp_col, precip_col]\n",
    "df_hourlyw = df_hourlyw[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hourlyw.to_csv('../Data/Weather Data/hourly_montreal_weather.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for the master data with columns from the stm data: date as date, dep_rl as start_time, ligne as line\n",
    "\n",
    "df_master = STM_df[['date', 'ligne', 'dep_rl', ]]\n",
    "df_master = df_master.rename(columns={'dep_rl': 'start_time', 'ligne': 'line'})\n",
    "df_hourlyw = pd.read_csv('../Data/Weather Data/hourly_montreal_weather.csv',  dtype={0: str, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str})\n",
    "df_dailyw = pd.read_csv('../Data/Weather Data/daily_montreal_weather.csv',  dtype={0: str, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str})\n",
    "df_hourlyw['date'] = pd.to_datetime(df_hourlyw['date'], errors='coerce')\n",
    "df_dailyw['date'] = pd.to_datetime(df_dailyw['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a actual temperature at start column (temp_start) to the master data, using the hourly weather data which matches the date and hour of the start time\n",
    "# Must create an hour columm in the master data to match the time column in the weather data\n",
    "# Must match the start hour with the next hour in the weather data since the weather time is the end of the hour\n",
    "\n",
    "df_master['hour'] = df_master['start_time'].str.slice(stop=2)\n",
    "df_master['hour'] = df_master['hour'].astype(int)\n",
    "df_master['hour'] = df_master['hour'] + 1\n",
    "df_master['hour'] = df_master['hour'].astype(str)\n",
    "df_master['hour'] = df_master['hour'].str.zfill(2)\n",
    "df_master['hour'] = df_master['hour'] + ':00'\n",
    "\n",
    "\n",
    "\n",
    "df_master = pd.merge(df_master, df_hourlyw, how='left', left_on=['date', 'hour'], right_on=['date', 'time'])\n",
    "df_master = df_master.rename(columns={'time': 'weather_time', 'temp': 'temp_start'})\n",
    "df_master = df_master.drop(columns=['hour', 'weather_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rain and snow amount columns to the master data, using the daily weather data which matches the date\n",
    "# For the snow_amt column, if the snow_yn column is Y, then take the value of the precip column, otherwise set to 0\n",
    "# For the rain_amt column, if the snow_yn column is N, then take the value of the precip column, otherwise set to 0\n",
    "\n",
    "df_master = pd.merge(df_master, df_dailyw, how='left', left_on=['date'], right_on=['date'])\n",
    "df_master = df_master.rename(columns={'precip': 'rain_amt'})\n",
    "df_master['snow_amt'] = np.where(df_master['snow_yn'] == 'Y', df_master['rain_amt'], 0)\n",
    "df_master['rain_amt'] = np.where(df_master['snow_yn'] == 'N', df_master['rain_amt'], 0)\n",
    "df_master = df_master.drop(columns=['snow_yn', 'snow'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert arrival and departure times to minutes after midnight to find delays\n",
    "#also convert start time to minutes after midnight (it is redundant with dep_rl but easier to work with)\n",
    "df_master['dep_pl'] = STM_df['dep_pl']\n",
    "df_master['dep_rl'] = STM_df['dep_rl']\n",
    "df_master['arr_pl'] = STM_df['arr_pl']\n",
    "df_master['arr_rl'] = STM_df['arr_rl']\n",
    "\n",
    "#make sure the time format is correct\n",
    "df_master[['start_time','dep_pl','dep_rl','arr_pl', 'arr_rl']] = df_master[['start_time','dep_pl','dep_rl','arr_pl', 'arr_rl']].astype(str).apply(lambda x: x.str.slice(stop=5))\n",
    "\n",
    "def time_to_minutes(time):\n",
    "    if pd.isna(time) or ':' not in time:\n",
    "        return np.nan\n",
    "    hours, minutes = time.split(':')\n",
    "    return int(hours) * 60 + int(minutes)\n",
    "try:\n",
    "    df_master[['start_time','dep_pl','dep_rl','arr_pl', 'arr_rl']] = df_master[['start_time','dep_pl','dep_rl','arr_pl', 'arr_rl']].astype(str).map(time_to_minutes)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while converting the Time: {e}\")\n",
    "\n",
    "# if pl > 1380 and rl < 60, then add 1440 to rl\n",
    "# if pl < 60 and rl > 1380, then add 1440 to pl\n",
    "\n",
    "df_master['dep_rl'] = np.where((df_master['dep_pl'] > 1380) & (df_master['dep_rl'] < 60), df_master['dep_rl'] + 1440, df_master['dep_rl'])\n",
    "df_master['dep_pl'] = np.where((df_master['dep_pl'] < 60) & (df_master['dep_rl'] > 1380), df_master['dep_pl'] + 1440, df_master['dep_pl'])\n",
    "df_master['arr_rl'] = np.where((df_master['arr_pl'] > 1380) & (df_master['arr_rl'] < 60), df_master['arr_rl'] + 1440, df_master['arr_rl'])\n",
    "df_master['arr_pl'] = np.where((df_master['arr_pl'] < 60) & (df_master['arr_rl'] > 1380), df_master['arr_pl'] + 1440, df_master['arr_pl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate delays\n",
    "df_master['delay_start'] = df_master['dep_rl'] - df_master['dep_pl']\n",
    "df_master['delay_end'] = df_master['arr_rl'] - df_master['arr_pl']\n",
    "\n",
    "\n",
    "df_master = df_master.drop(columns=['arr_pl', 'arr_rl', 'dep_pl', 'dep_rl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorganize columns\n",
    "\n",
    "cols = df_master.columns.tolist()\n",
    "date_col = cols[0]\n",
    "line_col = cols[1]\n",
    "delay_start_col = cols[6]\n",
    "cols = [col for col in cols if col not in {date_col, line_col, delay_start_col}]\n",
    "\n",
    "cols = [date_col, line_col, delay_start_col] + cols\n",
    "df_master = df_master[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date   line  delay_start  start_time temp_start rain_amt  \\\n",
      "167820 2022-03-20  139.0       1018.0        1143        3.6        0   \n",
      "211834 2022-05-03   67.0       1326.0        1200       15.8      0.0   \n",
      "314349 2022-08-24   80.0       1328.0        1155       24.8      0.0   \n",
      "361979 2022-10-15  121.0       1301.0         999       17.4      0.0   \n",
      "498645 2023-03-01  121.0      -1373.0         850        1.9        0   \n",
      "538896 2023-04-08   67.0       1352.0         799        4.5      0.0   \n",
      "\n",
      "       snow_amt  delay_end  \n",
      "167820      0.0       -1.0  \n",
      "211834        0        0.0  \n",
      "314349        0       -2.0  \n",
      "361979        0       -1.0  \n",
      "498645      0.0       23.0  \n",
      "538896        0       -4.0  \n",
      "             date   line  delay_start  start_time temp_start rain_amt  \\\n",
      "405769 2022-11-30   80.0        -50.0         794        7.1      2.4   \n",
      "429904 2022-12-24  121.0        -48.0         757       -8.4        0   \n",
      "460886 2023-01-24  121.0          0.0         816        1.5        0   \n",
      "\n",
      "       snow_amt  delay_end  \n",
      "405769        0     1357.0  \n",
      "429904      0.0     1351.0  \n",
      "460886      0.0    -1355.0  \n"
     ]
    }
   ],
   "source": [
    "# verify that there are no delays whose absolute value is greater than 10h\n",
    "# print as a list with the index and the delay value\n",
    "\n",
    "print(df_master[(df_master['delay_start'] > 1000) | (df_master['delay_start'] < -1000)])\n",
    "print(df_master[(df_master['delay_end'] > 1000) | (df_master['delay_end'] < -1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the file by line and date\n",
    "df_master = df_master.sort_values(by=['line', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change date column to day of week as a number (Monday = 0, Sunday = 6)\n",
    "df_master['date'] = df_master['date'].dt.dayofweek\n",
    "\n",
    "#rename columns\n",
    "df_master = df_master.rename(columns={'date': 'day_of_week'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 67.  80. 100. 121. 139. 439. 460. 467. 480.]\n",
      "[100. 121. 139. 439. 460. 467. 480.  67.  80.]\n"
     ]
    }
   ],
   "source": [
    "# show unique line values\n",
    "print(df_master['line'].unique())\n",
    "print(STM_df['ligne'].unique())\n",
    "#seems like the STM did not give me data for the 193 line ._."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add index column\n",
    "df_master = df_master.reset_index(drop=True)\n",
    "df_master = df_master.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>line</th>\n",
       "      <th>delay_start</th>\n",
       "      <th>start_time</th>\n",
       "      <th>temp_start</th>\n",
       "      <th>rain_amt</th>\n",
       "      <th>snow_amt</th>\n",
       "      <th>delay_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>309</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  day_of_week  line  delay_start  start_time temp_start rain_amt  \\\n",
       "0      0          1.0  67.0          0.0          17       15.1      0.0   \n",
       "1      1          1.0  67.0          0.0          41       15.1      0.0   \n",
       "2      2          1.0  67.0         -1.0          70       13.7      0.0   \n",
       "3      3          1.0  67.0         -1.0         309       11.8      0.0   \n",
       "4      4          1.0  67.0          0.0         337       11.8      0.0   \n",
       "\n",
       "  snow_amt  delay_end  \n",
       "0        0        3.0  \n",
       "1        0       10.0  \n",
       "2        0       -6.0  \n",
       "3        0       12.0  \n",
       "4        0        7.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.to_csv('../Data/master_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
